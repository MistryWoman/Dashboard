{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english')) \n",
    "punc = set([',', '-', '/', '.', '  ', 'university', 'research', 'center', 'institute'])\n",
    "stop_words.update(punc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>University/Organization</th>\n",
       "      <th>Paper_title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YoungMin Kwon</td>\n",
       "      <td>Microsoft Research</td>\n",
       "      <td>Passive Localization: Large Size Sensor Networ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gul Agha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Passive Localization: Large Size Sensor Networ...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jun-geun Park</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Moving-Baseline Localization</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erik D. Demaine</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Moving-Baseline Localization</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seth Teller</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Moving-Baseline Localization</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Volkan Cevher</td>\n",
       "      <td>Rice University</td>\n",
       "      <td>Pareto Frontiers of Sensor Networks for Locali...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lance Kaplan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pareto Frontiers of Sensor Networks for Locali...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasse Klingbeil</td>\n",
       "      <td>CSIRO</td>\n",
       "      <td>A Wireless Sensor Network for Real-Time Indoor...</td>\n",
       "      <td>2008</td>\n",
       "      <td>ipsn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Author_Name                University/Organization  \\\n",
       "0    YoungMin Kwon                     Microsoft Research   \n",
       "1         Gul Agha                                    NaN   \n",
       "2    Jun-geun Park  Massachusetts Institute of Technology   \n",
       "3  Erik D. Demaine  Massachusetts Institute of Technology   \n",
       "4      Seth Teller  Massachusetts Institute of Technology   \n",
       "5    Volkan Cevher                        Rice University   \n",
       "6     Lance Kaplan                                    NaN   \n",
       "7  Lasse Klingbeil                                  CSIRO   \n",
       "\n",
       "                                         Paper_title  Year Conference  \n",
       "0  Passive Localization: Large Size Sensor Networ...  2008       ipsn  \n",
       "1  Passive Localization: Large Size Sensor Networ...  2008       ipsn  \n",
       "2                       Moving-Baseline Localization  2008       ipsn  \n",
       "3                       Moving-Baseline Localization  2008       ipsn  \n",
       "4                       Moving-Baseline Localization  2008       ipsn  \n",
       "5  Pareto Frontiers of Sensor Networks for Locali...  2008       ipsn  \n",
       "6  Pareto Frontiers of Sensor Networks for Locali...  2008       ipsn  \n",
       "7  A Wireless Sensor Network for Real-Time Indoor...  2008       ipsn  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipsn_df = pd.read_csv('data/Clean_Authors/ipsn_authors.csv')\n",
    "ipsn_df = ipsn_df.drop(['Keywords'], axis = 1)\n",
    "ipsn_df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating fuzzy string match function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/komal/.local/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "key = 'University of Illinois Urbana - Champaign'\n",
    "value = 'University of Illinois at Urbana, Champaign'\n",
    "\n",
    "def clean(name):\n",
    "    name = name.lower()\n",
    "    clean_name = []\n",
    "    tok = word_tokenize(name)\n",
    "    for token in tok:\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "        else:\n",
    "            clean_name.append(token)\n",
    "    return \" \".join(clean_name)\n",
    "\n",
    "\n",
    "def fuzzy(key, value):\n",
    "    key = clean(key)\n",
    "    value = clean(value)\n",
    "    fuzz_score = fuzz.token_set_ratio(key, value)\n",
    "    return fuzz_score\n",
    "\n",
    "fuzzy('University of British Columbia', 'U British Columbia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a csv file to contain all the conferences TPC details\n",
    "\n",
    "ipsn_tpc = pd.read_csv('data/Clean_TPC/ipsn_clean.csv')\n",
    "ipsn_auth = pd.read_csv('data/Clean_Authors/ipsn_authors.csv')\n",
    "\n",
    "mobicom_tpc = pd.read_csv('data/Clean_TPC/mobicom_clean.csv')\n",
    "mobicom_auth = pd.read_csv('data/Clean_Authors/mobicom_authors.csv')\n",
    "\n",
    "mobihoc_tpc = pd.read_csv('data/Clean_TPC/mobihoc_clean.csv')\n",
    "mobihoc_auth = pd.read_csv('data/Clean_Authors/mobihoc_authors.csv')\n",
    "\n",
    "sensys_tpc = pd.read_csv('data/Clean_TPC/sensys_clean.csv')\n",
    "sensys_auth = pd.read_csv('data/Clean_Authors/sensys_authors.csv')\n",
    "\n",
    "sigcomm_tpc = pd.read_csv('data/Clean_TPC/sigcomm_clean.csv')\n",
    "sigcomm_auth = pd.read_csv('data/Clean_Authors/sigcomm_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpc_auth_pub(author_df, tpc_df):\n",
    "    \"Given the auth and tpc df for a conference returns \"\n",
    "    \n",
    "    tpc_count = collections.Counter(tpc_df['University/Organization'])\n",
    "    tpc_count_df = pd.DataFrame(list(zip(tpc_count.keys(), tpc_count.values())), columns = ['University/Organization', 'No_of_tpc'])\n",
    "\n",
    "    auth_count = collections.Counter(author_df['University/Organization'])\n",
    "    auth_count_df = pd.DataFrame(list(zip(auth_count.keys(), auth_count.values())), columns = ['University/Organization', 'No_of_authors'])\n",
    "\n",
    "    paper_uni = set()\n",
    "    uni_paper_dict = collections.defaultdict(int)\n",
    "    for index in range(len(ipsn_auth)):\n",
    "        uni = ipsn_auth['University/Organization'][index]\n",
    "        paper = ipsn_auth['Paper_title'][index]\n",
    "\n",
    "        paper_uni.add((uni, paper))\n",
    "\n",
    "    for pap_uni in paper_uni:\n",
    "        university, paper = pap_uni\n",
    "        if university not in uni_paper_dict.keys():\n",
    "            uni_paper_dict[university] = 1\n",
    "        elif university in uni_paper_dict.keys():\n",
    "            uni_paper_dict[university] += 1\n",
    "\n",
    "    pub_count = pd.DataFrame(list(zip(uni_paper_dict.keys(), uni_paper_dict.values())), columns = ['University/Organization', 'No_of_publications'])\n",
    "    \n",
    "    tpc_auth = pd.merge(left = tpc_count_df, right = auth_count_df, left_on='University/Organization', right_on='University/Organization')\n",
    "    \n",
    "    final_df = pd.merge(left = tpc_auth, right = pub_count, left_on='University/Organization', right_on='University/Organization')\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipsn_bubble = tpc_auth_pub(ipsn_auth, ipsn_tpc)\n",
    "ipsn_bubble.to_csv('data/Bubble/ipsn_bubble.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensys_bubble = tpc_auth_pub(sensys_auth, sensys_tpc)\n",
    "sensys_bubble.to_csv('data/Bubble/sensys_bubble.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigcomm_bubble = tpc_auth_pub(sigcomm_auth, sigcomm_tpc)\n",
    "sigcomm_bubble.to_csv('data/Bubble/sigcomm_bubble.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobicom_bubble = tpc_auth_pub(mobicom_auth, mobicom_tpc)\n",
    "mobicom_bubble.to_csv('data/Bubble/mobicom_bubble.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobihoc_bubble = tpc_auth_pub(mobihoc_auth, mobihoc_tpc)\n",
    "mobihoc_bubble.to_csv('data/Bubble/mobihoc_bubble.csv', header = True, index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
